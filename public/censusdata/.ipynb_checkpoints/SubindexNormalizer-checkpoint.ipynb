{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feecdf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing POPDENSITY values found.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Load the two GeoJSON files\n",
    "with open('atlanta_blockgroup_pdi_2013.geojson', 'r') as file:\n",
    "    geojson_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_pdi_2022.geojson', 'r') as file:\n",
    "    geojson_2022 = json.load(file)\n",
    "\n",
    "# Extract features from both GeoJSON files and add a year attribute\n",
    "features_2013 = geojson_2013['features']\n",
    "features_2022 = geojson_2022['features']\n",
    "\n",
    "for feature in features_2013:\n",
    "    feature['properties']['year'] = 2013\n",
    "for feature in features_2022:\n",
    "    feature['properties']['year'] = 2022\n",
    "\n",
    "# Combine features\n",
    "combined_features = features_2013 + features_2022\n",
    "\n",
    "# Create a DataFrame from the combined features\n",
    "data = [\n",
    "    {\n",
    "        'year': feature['properties']['year'],\n",
    "        'POPDENSITY': feature['properties'].get('POPDENSITY', 0),  # Default to 0 if POPDENSITY is missing\n",
    "        'properties': feature['properties'],  # Store properties for reconstruction\n",
    "        'geometry': feature['geometry']  # Store geometry for reconstruction\n",
    "    }\n",
    "    for feature in combined_features\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values in POPDENSITY\n",
    "if df['POPDENSITY'].isnull().any():\n",
    "    print(\"Warning: Missing POPDENSITY values found.\")\n",
    "    df['POPDENSITY'].fillna(0, inplace=True)  # Replace NaN values with 0 for ranking\n",
    "\n",
    "# Calculate percentile ranks of POPDENSITY across both years and scale between 0 and 1\n",
    "df['PDI'] = rankdata(df['POPDENSITY'], method='average') / len(df['POPDENSITY'])\n",
    "\n",
    "# Update the original features with the new PDI values\n",
    "for i, feature in enumerate(combined_features):\n",
    "    feature['properties']['PDI'] = df['PDI'].iloc[i]\n",
    "\n",
    "# Split the combined GeoJSON back into the original years\n",
    "features_2013_updated = [f for f in combined_features if f['properties']['year'] == 2013]\n",
    "features_2022_updated = [f for f in combined_features if f['properties']['year'] == 2022]\n",
    "\n",
    "# Overwrite the original GeoJSON files\n",
    "geojson_2013['features'] = features_2013_updated\n",
    "geojson_2022['features'] = features_2022_updated\n",
    "\n",
    "with open('atlanta_blockgroup_pdi_2013.geojson', 'w') as file:\n",
    "    json.dump(geojson_2013, file)\n",
    "\n",
    "with open('atlanta_blockgroup_pdi_2022.geojson', 'w') as file:\n",
    "    json.dump(geojson_2022, file)\n",
    "\n",
    "# Convert each GeoJSON back to CSV\n",
    "def geojson_to_csv(geojson_data, csv_path):\n",
    "    # Flatten the properties and geometry into a CSV-friendly format\n",
    "    rows = []\n",
    "    for feature in geojson_data['features']:\n",
    "        row = feature['properties'].copy()  # Start with properties\n",
    "        row['geometry_type'] = feature['geometry']['type']\n",
    "        row['coordinates'] = json.dumps(feature['geometry']['coordinates'])  # Serialize coordinates as string\n",
    "        rows.append(row)\n",
    "    # Convert to DataFrame and write to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Convert the updated GeoJSONs to CSV files with the original names\n",
    "geojson_to_csv(geojson_2013, 'atlanta_blockgroup_pdi_2013.csv')\n",
    "geojson_to_csv(geojson_2022, 'atlanta_blockgroup_pdi_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b746bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Load the two GeoJSON files\n",
    "with open('atlanta_blockgroup_cdi_2013.geojson', 'r') as file:\n",
    "    geojson_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_cdi_2022.geojson', 'r') as file:\n",
    "    geojson_2022 = json.load(file)\n",
    "\n",
    "# Extract features from both GeoJSON files and add a year attribute\n",
    "features_2013 = geojson_2013['features']\n",
    "features_2022 = geojson_2022['features']\n",
    "\n",
    "for feature in features_2013:\n",
    "    feature['properties']['year'] = 2013\n",
    "for feature in features_2022:\n",
    "    feature['properties']['year'] = 2022\n",
    "\n",
    "# Combine features\n",
    "combined_features = features_2013 + features_2022\n",
    "\n",
    "# Create a DataFrame from the combined features\n",
    "data = [\n",
    "    {\n",
    "        'year': feature['properties']['year'],\n",
    "        'commercial_density': feature['properties'].get('commercial_density', 0),  # Default to 0 if missing\n",
    "        'properties': feature['properties'],  # Store properties for reconstruction\n",
    "        'geometry': feature['geometry']  # Store geometry for reconstruction\n",
    "    }\n",
    "    for feature in combined_features\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values in commercial_density\n",
    "if df['commercial_density'].isnull().any():\n",
    "    print(\"Warning: Missing commercial_density values found.\")\n",
    "    df['commercial_density'].fillna(0, inplace=True)  # Replace NaN values with 0 for ranking\n",
    "\n",
    "# Calculate percentile ranks of commercial_density across both years and scale between 0 and 1\n",
    "df['CDI'] = rankdata(df['commercial_density'], method='average') / len(df['commercial_density'])\n",
    "\n",
    "# Update the original features with the new CDI values\n",
    "for i, feature in enumerate(combined_features):\n",
    "    feature['properties']['CDI'] = df['CDI'].iloc[i]\n",
    "\n",
    "# Split the combined GeoJSON back into the original years\n",
    "features_2013_updated = [f for f in combined_features if f['properties']['year'] == 2013]\n",
    "features_2022_updated = [f for f in combined_features if f['properties']['year'] == 2022]\n",
    "\n",
    "# Overwrite the original GeoJSON files\n",
    "geojson_2013['features'] = features_2013_updated\n",
    "geojson_2022['features'] = features_2022_updated\n",
    "\n",
    "with open('atlanta_blockgroup_cdi_2013.geojson', 'w') as file:\n",
    "    json.dump(geojson_2013, file)\n",
    "\n",
    "with open('atlanta_blockgroup_cdi_2022.geojson', 'w') as file:\n",
    "    json.dump(geojson_2022, file)\n",
    "\n",
    "# Convert each GeoJSON back to CSV\n",
    "def geojson_to_csv(geojson_data, csv_path):\n",
    "    # Flatten the properties and geometry into a CSV-friendly format\n",
    "    rows = []\n",
    "    for feature in geojson_data['features']:\n",
    "        row = feature['properties'].copy()  # Start with properties\n",
    "        row['geometry_type'] = feature['geometry']['type']\n",
    "        row['coordinates'] = json.dumps(feature['geometry']['coordinates'])  # Serialize coordinates as string\n",
    "        rows.append(row)\n",
    "    # Convert to DataFrame and write to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Convert the updated GeoJSONs to CSV files with the original names\n",
    "geojson_to_csv(geojson_2013, 'atlanta_blockgroup_cdi_2013.csv')\n",
    "geojson_to_csv(geojson_2022, 'atlanta_blockgroup_cdi_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9b8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Load the two GeoJSON files\n",
    "with open('atlanta_blockgroup_idi_2013.geojson', 'r') as file:\n",
    "    geojson_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_idi_2022.geojson', 'r') as file:\n",
    "    geojson_2022 = json.load(file)\n",
    "\n",
    "# Extract features from both GeoJSON files and add a year attribute\n",
    "features_2013 = geojson_2013['features']\n",
    "features_2022 = geojson_2022['features']\n",
    "\n",
    "for feature in features_2013:\n",
    "    feature['properties']['year'] = 2013\n",
    "for feature in features_2022:\n",
    "    feature['properties']['year'] = 2022\n",
    "\n",
    "# Combine features\n",
    "combined_features = features_2013 + features_2022\n",
    "\n",
    "# Create a DataFrame from the combined features\n",
    "data = [\n",
    "    {\n",
    "        'year': feature['properties']['year'],\n",
    "        'IDI': feature['properties'].get('IDI', 0),  # Default to 0 if IDI is missing\n",
    "        'properties': feature['properties'],  # Store properties for reconstruction\n",
    "        'geometry': feature['geometry']  # Store geometry for reconstruction\n",
    "    }\n",
    "    for feature in combined_features\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values in IDI\n",
    "if df['IDI'].isnull().any():\n",
    "    print(\"Warning: Missing IDI values found.\")\n",
    "    df['IDI'].fillna(0, inplace=True)  # Replace NaN values with 0 for ranking\n",
    "\n",
    "# Calculate percentile ranks of IDI across both years and scale between 0 and 1\n",
    "df['IDI'] = rankdata(df['IDI'], method='average') / len(df['IDI'])\n",
    "\n",
    "# Update the original features with the new IDI percentile rank values\n",
    "for i, feature in enumerate(combined_features):\n",
    "    feature['properties']['IDI'] = df['IDI'].iloc[i]\n",
    "\n",
    "# Split the combined GeoJSON back into the original years\n",
    "features_2013_updated = [f for f in combined_features if f['properties']['year'] == 2013]\n",
    "features_2022_updated = [f for f in combined_features if f['properties']['year'] == 2022]\n",
    "\n",
    "# Overwrite the original GeoJSON files\n",
    "geojson_2013['features'] = features_2013_updated\n",
    "geojson_2022['features'] = features_2022_updated\n",
    "\n",
    "with open('atlanta_blockgroup_idi_2013.geojson', 'w') as file:\n",
    "    json.dump(geojson_2013, file)\n",
    "\n",
    "with open('atlanta_blockgroup_idi_2022.geojson', 'w') as file:\n",
    "    json.dump(geojson_2022, file)\n",
    "\n",
    "# Convert each GeoJSON back to CSV\n",
    "def geojson_to_csv(geojson_data, csv_path):\n",
    "    # Flatten the properties and geometry into a CSV-friendly format\n",
    "    rows = []\n",
    "    for feature in geojson_data['features']:\n",
    "        row = feature['properties'].copy()  # Start with properties\n",
    "        row['geometry_type'] = feature['geometry']['type']\n",
    "        row['coordinates'] = json.dumps(feature['geometry']['coordinates'])  # Serialize coordinates as string\n",
    "        rows.append(row)\n",
    "    # Convert to DataFrame and write to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Convert the updated GeoJSONs to CSV files with the original names\n",
    "geojson_to_csv(geojson_2013, 'atlanta_blockgroup_idi_2013.csv')\n",
    "geojson_to_csv(geojson_2022, 'atlanta_blockgroup_idi_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1db671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Load the two GeoJSON files\n",
    "with open('atlanta_blockgroup_ldi_2013.geojson', 'r') as file:\n",
    "    geojson_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_ldi_2022.geojson', 'r') as file:\n",
    "    geojson_2022 = json.load(file)\n",
    "\n",
    "# Extract features from both GeoJSON files and add a year attribute\n",
    "features_2013 = geojson_2013['features']\n",
    "features_2022 = geojson_2022['features']\n",
    "\n",
    "for feature in features_2013:\n",
    "    feature['properties']['year'] = 2013\n",
    "for feature in features_2022:\n",
    "    feature['properties']['year'] = 2022\n",
    "\n",
    "# Combine features\n",
    "combined_features = features_2013 + features_2022\n",
    "\n",
    "# Create a DataFrame from the combined features\n",
    "data = [\n",
    "    {\n",
    "        'year': feature['properties']['year'],\n",
    "        'Entropy': feature['properties'].get('Entropy', 0),  # Default to 0 if entropy is missing\n",
    "        'properties': feature['properties'],  # Store properties for reconstruction\n",
    "        'geometry': feature['geometry']  # Store geometry for reconstruction\n",
    "    }\n",
    "    for feature in combined_features\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values in entropy\n",
    "if df['Entropy'].isnull().any():\n",
    "    print(\"Warning: Missing entropy values found.\")\n",
    "    df['Entropy'].fillna(0, inplace=True)  # Replace NaN values with 0 for ranking\n",
    "\n",
    "# Calculate percentile ranks of entropy across both years and scale between 0 and 1\n",
    "df['LDI'] = rankdata(df['Entropy'], method='average') / len(df['Entropy'])\n",
    "\n",
    "# Update the original features with the new LDI percentile rank values\n",
    "for i, feature in enumerate(combined_features):\n",
    "    feature['properties']['LDI'] = df['LDI'].iloc[i]\n",
    "\n",
    "# Split the combined GeoJSON back into the original years\n",
    "features_2013_updated = [f for f in combined_features if f['properties']['year'] == 2013]\n",
    "features_2022_updated = [f for f in combined_features if f['properties']['year'] == 2022]\n",
    "\n",
    "# Overwrite the original GeoJSON files\n",
    "geojson_2013['features'] = features_2013_updated\n",
    "geojson_2022['features'] = features_2022_updated\n",
    "\n",
    "with open('atlanta_blockgroup_ldi_2013.geojson', 'w') as file:\n",
    "    json.dump(geojson_2013, file)\n",
    "\n",
    "with open('atlanta_blockgroup_ldi_2022.geojson', 'w') as file:\n",
    "    json.dump(geojson_2022, file)\n",
    "\n",
    "# Convert each GeoJSON back to CSV\n",
    "def geojson_to_csv(geojson_data, csv_path):\n",
    "    # Flatten the properties and geometry into a CSV-friendly format\n",
    "    rows = []\n",
    "    for feature in geojson_data['features']:\n",
    "        row = feature['properties'].copy()  # Start with properties\n",
    "        row['geometry_type'] = feature['geometry']['type']\n",
    "        row['coordinates'] = json.dumps(feature['geometry']['coordinates'])  # Serialize coordinates as string\n",
    "        rows.append(row)\n",
    "    # Convert to DataFrame and write to CSV\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Convert the updated GeoJSONs to CSV files with the original names\n",
    "geojson_to_csv(geojson_2013, 'atlanta_blockgroup_ldi_2013.csv')\n",
    "geojson_to_csv(geojson_2022, 'atlanta_blockgroup_ldi_2022.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21d78d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swati\\AppData\\Local\\Temp\\ipykernel_28084\\753718325.py:52: FutureWarning: Passing 'suffixes' which cause duplicate columns {'geometry_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  data_2013 = pdi_2013_df.merge(idi_2013_df, on='geometry_str').merge(ldi_2013_df, on='geometry_str').merge(cdi_2013_df, on='geometry_str')\n",
      "C:\\Users\\swati\\AppData\\Local\\Temp\\ipykernel_28084\\753718325.py:53: FutureWarning: Passing 'suffixes' which cause duplicate columns {'geometry_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  data_2022 = pdi_2022_df.merge(idi_2022_df, on='geometry_str').merge(ldi_2022_df, on='geometry_str').merge(cdi_2022_df, on='geometry_str')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column geometry",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m data_2022 \u001b[38;5;241m=\u001b[39m pdi_2022_df\u001b[38;5;241m.\u001b[39mmerge(idi_2022_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_str\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmerge(ldi_2022_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_str\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmerge(cdi_2022_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_str\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Retain the geometry column from the first metric (same geometry across all columns)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m data_2013[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_2013[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_x\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# or whichever geometry column is available\u001b[39;00m\n\u001b[0;32m     57\u001b[0m data_2022[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_2022[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry_x\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Calculate PEI for each year\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4125\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 4125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame with multiple columns to the single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4128\u001b[0m     )\n\u001b[0;32m   4130\u001b[0m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m value[value\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column geometry"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Load the GeoJSON files for each metric\n",
    "with open('atlanta_blockgroup_pdi_2013.geojson', 'r') as file:\n",
    "    pdi_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_pdi_2022.geojson', 'r') as file:\n",
    "    pdi_2022 = json.load(file)\n",
    "\n",
    "with open('atlanta_blockgroup_idi_2013.geojson', 'r') as file:\n",
    "    idi_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_idi_2022.geojson', 'r') as file:\n",
    "    idi_2022 = json.load(file)\n",
    "\n",
    "with open('atlanta_blockgroup_ldi_2013.geojson', 'r') as file:\n",
    "    ldi_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_ldi_2022.geojson', 'r') as file:\n",
    "    ldi_2022 = json.load(file)\n",
    "\n",
    "with open('atlanta_blockgroup_cdi_2013.geojson', 'r') as file:\n",
    "    cdi_2013 = json.load(file)\n",
    "with open('atlanta_blockgroup_cdi_2022.geojson', 'r') as file:\n",
    "    cdi_2022 = json.load(file)\n",
    "\n",
    "# Function to create a DataFrame from a GeoJSON file, with geometry as a key\n",
    "def geojson_to_dataframe(geojson_data, metric_name):\n",
    "    data = []\n",
    "    for feature in geojson_data['features']:\n",
    "        geometry_str = json.dumps(feature['geometry']['coordinates'])  # Standardized string of coordinates only\n",
    "        data.append({\n",
    "            'geometry_str': geometry_str,\n",
    "            metric_name: feature['properties'].get(metric_name, 0),  # Default to 0 if missing\n",
    "            'geometry': feature['geometry']  # Keep geometry as a dictionary\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Convert each GeoJSON to DataFrames for easy merging\n",
    "pdi_2013_df = geojson_to_dataframe(pdi_2013, 'PDI')\n",
    "pdi_2022_df = geojson_to_dataframe(pdi_2022, 'PDI')\n",
    "\n",
    "idi_2013_df = geojson_to_dataframe(idi_2013, 'IDI')\n",
    "idi_2022_df = geojson_to_dataframe(idi_2022, 'IDI')\n",
    "\n",
    "ldi_2013_df = geojson_to_dataframe(ldi_2013, 'LDI')\n",
    "ldi_2022_df = geojson_to_dataframe(ldi_2022, 'LDI')\n",
    "\n",
    "cdi_2013_df = geojson_to_dataframe(cdi_2013, 'CDI')\n",
    "cdi_2022_df = geojson_to_dataframe(cdi_2022, 'CDI')\n",
    "\n",
    "# Merge the DataFrames for each year on geometry_str to combine all metrics\n",
    "data_2013 = pdi_2013_df.merge(idi_2013_df, on='geometry_str').merge(ldi_2013_df, on='geometry_str').merge(cdi_2013_df, on='geometry_str')\n",
    "data_2022 = pdi_2022_df.merge(idi_2022_df, on='geometry_str').merge(ldi_2022_df, on='geometry_str').merge(cdi_2022_df, on='geometry_str')\n",
    "\n",
    "# Explicitly select and retain only one 'geometry' column after merging\n",
    "data_2013['geometry'] = data_2013['geometry_x']\n",
    "data_2022['geometry'] = data_2022['geometry_x']\n",
    "\n",
    "# Drop any extra geometry columns created during the merge\n",
    "data_2013 = data_2013.drop(columns=[col for col in data_2013.columns if col.startswith('geometry_') and col != 'geometry'])\n",
    "data_2022 = data_2022.drop(columns=[col for col in data_2022.columns if col.startswith('geometry_') and col != 'geometry'])\n",
    "\n",
    "\n",
    "# Calculate PEI for each year\n",
    "data_2013['PEI'] = ((1 + data_2013['PDI']) * (1 + data_2013['IDI']) * (1 + data_2013['LDI']) * (1 + data_2013['CDI'])) / 16\n",
    "data_2022['PEI'] = ((1 + data_2022['PDI']) * (1 + data_2022['IDI']) * (1 + data_2022['LDI']) * (1 + data_2022['CDI'])) / 16\n",
    "\n",
    "# Add the year to each DataFrame\n",
    "data_2013['year'] = 2013\n",
    "data_2022['year'] = 2022\n",
    "\n",
    "# Select only the required columns\n",
    "data_2013 = data_2013[['geometry', 'year', 'PEI']]\n",
    "data_2022 = data_2022[['geometry', 'year', 'PEI']]\n",
    "\n",
    "# Convert to GeoJSON format\n",
    "def dataframe_to_geojson(data, output_file):\n",
    "    features = []\n",
    "    for _, row in data.iterrows():\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"year\": row['year'],\n",
    "                \"PEI\": row['PEI']\n",
    "            },\n",
    "            \"geometry\": row['geometry']\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(geojson, file)\n",
    "\n",
    "# Save as GeoJSON\n",
    "dataframe_to_geojson(data_2013, 'atlanta_blockgroup_pei_2013.geojson')\n",
    "dataframe_to_geojson(data_2022, 'atlanta_blockgroup_pei_2022.geojson')\n",
    "\n",
    "# Convert to CSV\n",
    "def dataframe_to_csv(data, output_file):\n",
    "    # Flatten the geometry for CSV export\n",
    "    rows = []\n",
    "    for _, row in data.iterrows():\n",
    "        row_data = {\n",
    "            \"year\": row['year'],\n",
    "            \"PEI\": row['PEI'],\n",
    "            \"geometry_type\": row['geometry']['type'],\n",
    "            \"coordinates\": json.dumps(row['geometry']['coordinates'])\n",
    "        }\n",
    "        rows.append(row_data)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "# Save as CSV\n",
    "dataframe_to_csv(data_2013, 'atlanta_blockgroup_pei_2013.csv')\n",
    "dataframe_to_csv(data_2022, 'atlanta_blockgroup_pei_2022.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3582925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont have "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
